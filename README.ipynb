{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f4206d20",
   "metadata": {},
   "source": [
    "# Graphcore Poplar Path-Tracer on Gradient\n",
    "\n",
    "This notebook contains the instructions to build and run a [Poplar C++ Ray/Path Tracer](https://github.com/markp-gc/ipu_ray_lib) for Graphcore IPUs. This notebook demonstrates how to render a path-traced image and also how analyse the correctness of the ray-tracer by comparing its output with [Embree](https://www.embree.org).\n",
    "\n",
    "![Suzanne Path-Traced on IPU](images/monkey_bust_16384spp.png)\n",
    "\n",
    "## Instructions\n",
    "\n",
    "First you need to launch an IPU machine: click the 'start machine' button above.\n",
    "\n",
    "![Start Machine Screenshot](images/start_machine.png)\n",
    "\n",
    "### Fetch and Build the Code\n",
    "\n",
    "We can execute these shell commands to build the application. The build uses CMake:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de4cfb7-1c6e-4ad1-890d-dcd211334bfe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-10T16:25:04.773610Z",
     "iopub.status.busy": "2023-01-10T16:25:04.773333Z",
     "iopub.status.idle": "2023-01-10T16:25:05.554944Z",
     "shell.execute_reply": "2023-01-10T16:25:05.554395Z",
     "shell.execute_reply.started": "2023-01-10T16:25:04.773583Z"
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "!cd ipu_ray_lib && git pull\n",
    "!mkdir -p ipu_ray_lib/build\n",
    "!cd ipu_ray_lib/build && cmake -Wno-dev -G Ninja .. && ninja -j64"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5e79d8cd-4cca-49d4-9df4-fff6e3baf42d",
   "metadata": {},
   "source": [
    "### Run the Application\n",
    "\n",
    "Ray data is distributed across all tiles (cores) but the scene data (BVH) is currently replicated across all tiles. This means meshes need to fit on one tile. You can specify your own scenes using the `--mesh-file` option but there is a built-in scene which is rendered if no file is specified. To render it execute the following cell: after ~30 seconds it will output an EXR image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2b07c6-e572-435d-a9c8-a8aad8beaa67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-10T16:25:05.556220Z",
     "iopub.status.busy": "2023-01-10T16:25:05.555930Z",
     "iopub.status.idle": "2023-01-10T16:25:31.152592Z",
     "shell.execute_reply": "2023-01-10T16:25:31.151962Z",
     "shell.execute_reply.started": "2023-01-10T16:25:05.556200Z"
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "!cd ipu_ray_lib/build && ./trace -w 1440 -h 1440 --render-mode path-trace --visualise rgb --samples 1000 --ipus 4 --ipu-only"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7678c0fc-2116-4344-bc5d-bb875284ab00",
   "metadata": {},
   "source": [
    "The resulting image is high dynamic range (HDR) in EXR format. We can make a function\n",
    "to perform a quick tone-mapping and display the resulting image in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784f56d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-10T16:25:31.154052Z",
     "iopub.status.busy": "2023-01-10T16:25:31.153872Z",
     "iopub.status.idle": "2023-01-10T16:25:32.669425Z",
     "shell.execute_reply": "2023-01-10T16:25:32.668805Z",
     "shell.execute_reply.started": "2023-01-10T16:25:31.154032Z"
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Function to apply simple gamma correction, rescale,\n",
    "# and clip values into range 0-255:\n",
    "def gamma_correct(x, exposure, gamma):\n",
    "  scale = 2.0 ** exposure\n",
    "  y = np.power(x * scale, 1.0 / gamma) * 255.0\n",
    "  return np.clip(y, 0.0, 255.0)\n",
    "\n",
    "# Function to plot an opencv image:\n",
    "def display_image(img):\n",
    "  plt.figure(figsize=(8, 8))\n",
    "  plt.style.use('dark_background')\n",
    "  plt.imshow(cv2.cvtColor(ldr, cv2.COLOR_BGR2RGB), interpolation='bicubic')\n",
    "  plt.show()\n",
    "\n",
    "EXR_FLAGS = cv2.IMREAD_UNCHANGED | cv2.IMREAD_ANYCOLOR | cv2.IMREAD_ANYDEPTH\n",
    "hdr = cv2.imread('ipu_ray_lib/build/out_rgb_ipu.exr', EXR_FLAGS)\n",
    "print(f\"HDR image shape: {hdr.shape} type: {hdr.dtype} min: {np.min(hdr)} max: {np.max(hdr)}\")\n",
    "\n",
    "ldr = gamma_correct(hdr, exposure=1.2, gamma=2.4).astype(np.uint8)\n",
    "cv2.imwrite('tonemapped.png', ldr)\n",
    "display_image(ldr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2cde1d64",
   "metadata": {},
   "source": [
    "You can open or download the saved result [tonemapped.png](tonemapped.png) in the file browser on the left. You may have to click on the refresh icon to update the view of the files.\n",
    "\n",
    "If you want to render a CPU reference image remove the option `--ipu-only` but be aware it will take\n",
    "much much longer to render. (For a list of all command options run `./test --help`.)\n",
    "\n",
    "If you just want to compare arbitrary output variables (AOVs) between CPU/Embree/IPU you can\n",
    "change to a quicker render mode. For example to compare normals run this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d011ec7-708b-42a1-914d-0d17157e5672",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-10T16:25:32.670659Z",
     "iopub.status.busy": "2023-01-10T16:25:32.670411Z",
     "iopub.status.idle": "2023-01-10T16:25:51.590461Z",
     "shell.execute_reply": "2023-01-10T16:25:51.589697Z",
     "shell.execute_reply.started": "2023-01-10T16:25:32.670631Z"
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "!cd ipu_ray_lib/build && ./trace -w 1440 -h 1440 --render-mode shadow-trace --visualise normal --ipus 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87524c7-f6be-4712-99d8-712735eb96c1",
   "metadata": {},
   "source": [
    "Once the outputs are ready we can load them into Python to compare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1529e6c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-10T16:25:51.591793Z",
     "iopub.status.busy": "2023-01-10T16:25:51.591600Z",
     "iopub.status.idle": "2023-01-10T16:25:52.515071Z",
     "shell.execute_reply": "2023-01-10T16:25:52.514391Z",
     "shell.execute_reply.started": "2023-01-10T16:25:51.591773Z"
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Load normals:\n",
    "ipu_normals = cv2.imread('ipu_ray_lib/build/out_normal_ipu.exr', EXR_FLAGS)\n",
    "cpu_normals = cv2.imread('ipu_ray_lib/build/out_normal_cpu.exr', EXR_FLAGS)\n",
    "embree_normals = cv2.imread('ipu_ray_lib/build/out_normal_embree.exr', EXR_FLAGS)\n",
    "\n",
    "compare = ipu_normals\n",
    "abs_err = np.abs(compare - embree_normals)\n",
    "print(f\"IPU normals min: {np.min(compare)} max: {np.max(compare)}\")\n",
    "print(f\"Embree normals min: {np.min(embree_normals)} max: {np.max(embree_normals)}\")\n",
    "print(f\"ABS Error min: {np.min(abs_err)} max: {np.max(abs_err)} mean: {np.mean(abs_err)}\")\n",
    "\n",
    "# Plot them side by side:\n",
    "vis = ((compare + 1.0) / 2.0)\n",
    "vis_embree = ((embree_normals + 1.0) / 2.0)\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, sharey=True, figsize=(16, 8))\n",
    "ax[0].imshow(vis)\n",
    "ax[0].set_title('IPU')\n",
    "ax[1].imshow(vis_embree)\n",
    "ax[1].set_title('Embree')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "59b8e962",
   "metadata": {},
   "source": [
    "We can plot an error histogram (using a log scale because the error counts are small). As you can see most errors are tiny but there are a few outliers - these will be rays that hit alternative (i.e. possibly valid within machine precision) objects due to differences between our intersection test code and Embree's:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc034557",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(abs_err.flatten(), bins=300, range=[0.0, np.max(abs_err)], log=True)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "31e4d5aa",
   "metadata": {},
   "source": [
    "#### Render the Teaser Image\n",
    "\n",
    "Finally we can render the teaser image from the top of the page. That was a crop from an 8k image rendered to 16k samples per pixel using 8 IPUs. To get the result a bit quicker we can specify that we only want to render the cropped region like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dda4b8",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "!cd ipu_ray_lib/build && ./trace --render-mode path-trace --visualise rgb --ipus 4 --ipu-only -w 5760 -h 5760 --crop 1360x1060+2644+2860 --samples 10000"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b6755981",
   "metadata": {},
   "source": [
    "This should take about two minutes to take 10 thousand samples per pixel. Finally, we can tone map and display the rendered region and save in [teaser.png](teaser.png):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd98187",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "hdr = cv2.imread('ipu_ray_lib/build/out_rgb_ipu.exr', EXR_FLAGS)\n",
    "print(f\"Input shape: {hdr.shape}\")\n",
    "# slice out the rendered region:\n",
    "w = 1360\n",
    "h = 1060\n",
    "c = 2644\n",
    "r = 2860\n",
    "hdr = hdr[r:r+h, c:c+w, :]\n",
    "print(f\"Cropped shape: {hdr.shape}\")\n",
    "ldr = gamma_correct(hdr, exposure=1.0, gamma=2.66).astype(np.uint8)\n",
    "cv2.imwrite('teaser.png', ldr)\n",
    "display_image(ldr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c349a5a4",
   "metadata": {},
   "source": [
    "### Enjoy\n",
    "\n",
    "Although the program is currently limited in the size of BVH it can render it is very fast due to the IPU's large scale mulitple-instruction-multiple-data (MIMD) parallelism. It is a useful tool for experimenting or learning about path-tracing\n",
    "because you can render high resolution results much faster than you can on CPU with simple C++ code. For example, the IPU\n",
    "kernel code is uncomplicated, the path-trace inner loop looks like this:\n",
    "```C++\n",
    "  for (auto i = 0u; i < maxPathLength; ++i) {\n",
    "    // offset rays to avoid self intersection:\n",
    "    offsetRay(hit.r, hit.normal);\n",
    "    // Reset ray limits for next bounce:\n",
    "    hit.r.tMin = 0.f;\n",
    "    hit.r.tMax = std::numeric_limits<float>::infinity();\n",
    "    auto intersected = bvh.intersect(hit.r, primLookup);\n",
    "\n",
    "    if (intersected) {\n",
    "      updateHit(intersected, hit);\n",
    "      const auto& material = wrappedMaterials[wrappedMatIDs[hit.geomID]];\n",
    "\n",
    "      if (material.emissive) {\n",
    "        color += throughput * material.emission;\n",
    "      }\n",
    "\n",
    "      if (material.type == Material::Type::Diffuse) {\n",
    "        // Use HW random number generator for samples:\n",
    "        const float u1 = hw_uniform_0_1();\n",
    "        const float u2 = hw_uniform_0_1();\n",
    "        hit.r.direction = sampleDiffuse(hit.normal, u1, u2);\n",
    "        // Update throughput:\n",
    "        throughput *= material.albedo;\n",
    "      } else if (material.type == Material::Type::Specular) {\n",
    "        hit.r.direction = reflect(hit.r.direction, hit.normal);\n",
    "        throughput *= material.albedo;\n",
    "      } else if (material.type == Material::Type::Refractive) {\n",
    "        const float u1 = hw_uniform_0_1();\n",
    "        const auto [dir, refracted] = dielectric(hit.r, hit.normal, material.ior, u1);\n",
    "        hit.r.direction = dir;\n",
    "        if (refracted) { throughput *= material.albedo; }\n",
    "      } else {\n",
    "        // Mark an error:\n",
    "        result.rgb *= std::numeric_limits<float>::quiet_NaN();\n",
    "      }\n",
    "    } else {\n",
    "      break;\n",
    "    }\n",
    "\n",
    "    // Random stopping:\n",
    "    if (i > rouletteStartDepth) {\n",
    "      const float u1 = hw_uniform_0_1();\n",
    "      if (evaluateRoulette(u1, throughput)) { break; }\n",
    "    }\n",
    "  }\n",
    "```\n",
    "\n",
    "If you want to browse the code here are some good starting points:\n",
    "\n",
    "- [TraceCodelets.cpp](ipu_ray_lib/codelets/TraceCodelets.cpp): IPU ray-tracing and path-tracing C++ kernels.\n",
    "- [trace.cpp](ipu_ray_lib/trace.cpp): The main program. In particular note the functions: `renderEmbree`, `renderCPU`, `renderIPU`.\n",
    "- [IpuScene.cpp](ipu_ray_lib/src/IpuScene.cpp): This compiles the IPU ray/path trace graph program using the Poplar graph compiler.\n",
    "- [CompactBVH2Node.hpp](ipu_ray_lib/include/CompactBVH2Node.hpp): Reduced precision BVH node structure used on the IPU (24 bytes per node).\n",
    "- [README.md](ipu_ray_lib/README.md): Contains more information about how the program works and its origins.\n",
    "\n",
    "If you want to make significant changes then you will need to consult the [Poplar SDK documentation](https://docs.graphcore.ai/projects/poplar-user-guide/en/latest/introduction.html).\n",
    "\n",
    "If you want more speed you can try a BOW-POD where the IPUs are clocked\n",
    "40% higher than on a standard POD.\n",
    "\n",
    "It is possible to export simple scenes from [Blender](https://www.blender.org) to render but material import is a little limited at the moment. An example scene exported to DAE format is provided in the assets folder: [DAE file](ipu_ray_lib/assets/test_scene.dae). That file is human readable which can help in understanding how the importer interprets it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "vscode": {
   "interpreter": {
    "hash": "c9ad4864c9c721810277722a61cd300684ef18a24cb01fc57b2c480710a554dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
